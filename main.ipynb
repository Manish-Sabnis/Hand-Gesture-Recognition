{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a665e633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756651630.835504   11589 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1756651630.910067   12460 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.163.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "W0000 00:00:1756651630.917570   12447 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756651630.925435   12444 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "# Utility to check if a finger is up\n",
    "def is_finger_up(landmarks, tip_id, mcp_id, palm_facing_camera):\n",
    "    \"\"\"\n",
    "    Returns True if the finger is extended.\n",
    "    Uses y-coordinates when palm faces camera.\n",
    "    Flips logic when back of hand faces camera.\n",
    "    \"\"\"\n",
    "    if palm_facing_camera:\n",
    "        return landmarks[tip_id].y < landmarks[mcp_id].y\n",
    "    else:\n",
    "        return landmarks[tip_id].y > landmarks[mcp_id].y\n",
    "\n",
    "\n",
    "def is_thumb_up(landmarks, hand_label):\n",
    "    \"\"\"\n",
    "    Thumb points outward differently for Left vs Right hand.\n",
    "    \"\"\"\n",
    "    if hand_label == \"Right\":\n",
    "        return landmarks[4].x < landmarks[3].x\n",
    "    else:  # Left hand\n",
    "        return landmarks[4].x > landmarks[3].x\n",
    "\n",
    "\n",
    "def detect_gesture(landmarks, hand_label):\n",
    "    \"\"\"\n",
    "    Classifies gesture based on landmark positions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Estimate palm orientation: check z of fingertips vs MCP\n",
    "    # If fingertips closer to camera (smaller z) -> palm facing camera\n",
    "    palm_facing = landmarks[8].z < landmarks[5].z  # index tip vs base\n",
    "\n",
    "    # Finger checks\n",
    "    index_up = is_finger_up(landmarks, 8, 5, palm_facing)\n",
    "    middle_up = is_finger_up(landmarks, 12, 9, palm_facing)\n",
    "    ring_up = is_finger_up(landmarks, 16, 13, palm_facing)\n",
    "    pinky_up = is_finger_up(landmarks, 20, 17, palm_facing)\n",
    "    thumb_up = is_thumb_up(landmarks, hand_label)\n",
    "\n",
    "    # Gesture rules\n",
    "    if index_up and middle_up and ring_up and pinky_up and thumb_up:\n",
    "        return \"Open Palm\"\n",
    "    elif not index_up and not middle_up and not ring_up and not pinky_up and not thumb_up:\n",
    "        return \"Fist\"\n",
    "    elif index_up and middle_up and not ring_up and not pinky_up:\n",
    "        return \"Peace\"\n",
    "    elif thumb_up and not index_up and not middle_up and not ring_up and not pinky_up:\n",
    "        return \"Thumbs Up\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ") as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip and convert to RGB\n",
    "        image = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Back to BGR for display\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        gesture_name = \"No Hand\"\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                hand_label = results.multi_handedness[idx].classification[0].label  # 'Left' or 'Right'\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS\n",
    "                )\n",
    "                gesture_name = detect_gesture(hand_landmarks.landmark, hand_label)\n",
    "\n",
    "        # Show gesture name\n",
    "        cv2.putText(image, gesture_name, (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Hand Gesture Recognition\", image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == 27:  # ESC to quit\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
